<!DOCTYPE html>
<html lang="en"><head>
<script src="week-03-rag_files/libs/clipboard/clipboard.min.js"></script>
<script src="week-03-rag_files/libs/quarto-html/tabby.min.js"></script>
<script src="week-03-rag_files/libs/quarto-html/popper.min.js"></script>
<script src="week-03-rag_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="week-03-rag_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="week-03-rag_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="week-03-rag_files/libs/quarto-html/quarto-syntax-highlighting-5efccf03a38e129e6e5ca76dade02d11.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.40">

  <meta name="author" content="Amit Arora">
  <title>Week 3: Retrieval Augumented Generation (RAG) - Part 1</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="week-03-rag_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="week-03-rag_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #cbccc6; background-color: #1f2430; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #cbccc6; } /* Normal */
    code span.al { color: #ff3333; background-color: #332430; font-weight: bold; } /* Alert */
    code span.an { color: #ffe6b3; } /* Annotation */
    code span.at { color: #73d0ff; } /* Attribute */
    code span.bn { color: #ffcc66; } /* BaseN */
    code span.bu { color: #95e6cb; } /* BuiltIn */
    code span.cf { color: #ffa759; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #95e6cb; } /* Char */
    code span.cn { color: #d4bfff; } /* Constant */
    code span.co { color: #5c6773; font-style: italic; } /* Comment */
    code span.cv { color: #d4bfff; } /* CommentVar */
    code span.do { color: #5c6773; } /* Documentation */
    code span.dt { color: #ffa759; } /* DataType */
    code span.dv { color: #ffcc66; } /* DecVal */
    code span.er { color: #ff3333; text-decoration: underline; } /* Error */
    code span.ex { color: #73d0ff; font-weight: bold; } /* Extension */
    code span.fl { color: #ffcc66; } /* Float */
    code span.fu { color: #ffd580; } /* Function */
    code span.im { color: #bae67e; } /* Import */
    code span.in { color: #ffcc66; } /* Information */
    code span.kw { color: #ffa759; font-weight: bold; } /* Keyword */
    code span.op { color: #f29e74; } /* Operator */
    code span.ot { color: #5ccfe6; } /* Other */
    code span.pp { color: #f28779; } /* Preprocessor */
    code span.re { color: #73d0ff; background-color: #2a4254; } /* RegionMarker */
    code span.sc { color: #95e6cb; } /* SpecialChar */
    code span.ss { color: #95e6cb; } /* SpecialString */
    code span.st { color: #bae67e; } /* String */
    code span.va { color: #5ccfe6; } /* Variable */
    code span.vs { color: #bae67e; } /* VerbatimString */
    code span.wa { color: #f28779; } /* Warning */
  </style>
  <link rel="stylesheet" href="week-03-rag_files/libs/revealjs/dist/theme/quarto-138bffa59e0b8e1d219a851a91faec2e.css">
  <link href="week-03-rag_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="week-03-rag_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="week-03-rag_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="week-03-rag_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Week 3: Retrieval Augumented Generation (RAG) - Part 1</h1>
  <p class="subtitle">Applied Generative AI for AI Developers</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Amit Arora 
</div>
</div>
</div>

</section>
<section id="what-is-rag" class="slide level2 center">
<h2>What is RAG?</h2>
<p>RAG = Retrieval Augumented Generation<br>
A generative AI approach where the model combines external knowledge retrieval with text generation to provide more accurate and contextually rich responses.</p>
</section>
<section id="why-rag" class="slide level2">
<h2>Why RAG?</h2>
<ul>
<li><p><strong>Augments LLM responses with relevant context</strong>: Instead of relying solely on the LLM’s training data, RAG retrieves and incorporates specific, up-to-date information into responses.</p></li>
<li><p><strong>Helps ground responses in factual information</strong>: By providing relevant context from trusted sources, RAG ensures responses are based on actual facts rather than model-generated content.</p></li>
<li><p><strong>Reduces hallucinations</strong>: With access to specific, retrieved information, the model is less likely to generate incorrect or fabricated responses.</p></li>
<li><p><strong>Enables use of private/proprietary data</strong>: Organizations can leverage their internal documents, knowledge bases, and proprietary information that wasn’t part of the LLM’s training data.</p></li>
<li><p><strong>Provides source attribution</strong>: RAG systems can track where information comes from, making responses more transparent and verifiable.</p></li>
</ul>
</section>
<section id="simple-rag-architecture" class="slide level2">
<h2>Simple RAG Architecture</h2>
<div class="callout callout-none no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="img/rag-simple.png"></p>
<figcaption>RAG simple</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>Key Components:</p>
<ul>
<li><strong>Document Processing</strong>: Converts raw documents into chunks and creates embeddings for efficient retrieval.</li>
<li><strong>Vector Storage</strong>: Stores document embeddings and enables similarity search.</li>
<li><strong>Query Processing</strong>: Converts user questions into embeddings and finds relevant documents.</li>
<li><strong>Response Generation</strong>: Combines retrieved context with LLM capabilities to generate accurate answers.</li>
</ul>
</section>
<section id="building-a-basic-rag-app" class="slide level2">
<h2>Building a Basic RAG App</h2>
<ol type="1">
<li><p><strong>Prepare documents</strong>: Clean and preprocess your source documents, removing irrelevant content and standardizing format.</p></li>
<li><p><strong>Create embeddings</strong>: Convert text chunks into numerical vectors using embedding models like <a href="https://huggingface.co/BAAI/bge-large-en-v1.5">BGE-large-en-v1.5</a> (available on Hugging Face), Amazon Titan embeddings, OpenAI’s ada-002 or Cohere’s embed-multilingual.</p></li>
<li><p><strong>Store in vector database</strong>: Upload embeddings to a vector store like Pinecone, Weaviate, or FAISS for efficient similarity search.</p></li>
<li><p><strong>Process user query</strong>: Convert the user’s question into an embedding using the same embedding model.</p></li>
<li><p><strong>Retrieve relevant context</strong>: Perform similarity search to find the most relevant document chunks.</p></li>
<li><p><strong>Generate response</strong>: Combine retrieved context with an LLM prompt to generate an accurate, contextual response.</p></li>
</ol>
</section>
<section id="chunking-strategies" class="slide level2">
<h2>Chunking Strategies</h2>
<blockquote>
<p>Reference: <a href="https://blog.lancedb.com/chunking-techniques-with-langchain-and-llamaindex/">Chunking techniques with LangChain and LllamaIndex</a></p>
</blockquote>
<ul>
<li><p><strong>Document segmentation approaches</strong>: Choose between fixed-size chunks, semantic chunking, or paragraph-based splitting depending on your content structure.</p></li>
<li><p><strong>Chunk size considerations</strong>: Balance between too large (dilutes relevance) and too small (loses context) - typically 256-1024 tokens works well.</p></li>
<li><p><strong>Overlap between chunks</strong>: Include some overlap (10-20%) between consecutive chunks to maintain context across boundaries.</p></li>
<li><p><strong>Maintaining context</strong>: Preserve important metadata and hierarchical information when splitting documents.</p></li>
<li><p><strong>Structured vs unstructured data</strong>: Adapt chunking strategy based on whether you’re dealing with free text, tables, or structured documents.</p></li>
</ul>
</section>
<section id="embeddings-deep-dive" class="slide level2">
<h2>Embeddings Deep Dive</h2>
<p>Key Considerations:</p>
<ul>
<li><p><strong>Model selection criteria</strong>: Consider factors like accuracy, speed, cost, and dimension size when choosing an embedding model.</p></li>
<li><p><strong>Dimensionality impact</strong>: Higher dimensions can capture more information but increase storage costs and retrieval time.</p></li>
<li><p><strong>Multi-lingual support</strong>: Choose models like Cohere multilingual or Amazon Titan if your application needs to handle multiple languages.</p></li>
<li><p><strong>Domain-specific needs</strong>: Consider fine-tuning embedding models for specialized domains like medical or legal text. Finet-tuning using <a href="https://huggingface.co/blog/train-sentence-transformers">Sentence Transformers</a>.</p></li>
</ul>
</section>
<section id="popular-embeddings-models" class="slide level2">
<h2>Popular Embeddings Models</h2>
<ul>
<li><strong>Hugging Face</strong>: Huge collection of embeddings models available</li>
<li><strong>OpenAI embeddings</strong>: Excellent general-purpose performance but can be expensive for large-scale applications.</li>
<li><strong>Cohere embeddings</strong>: Strong multilingual support and competitive performance.</li>
<li><strong>Amazon Titan</strong>: Integrated well with AWS ecosystem, good multilingual capabilities.</li>
<li><strong>ColBERTv2</strong>: Advanced model with strong performance on academic benchmarks. <a href="https://arxiv.org/pdf/2112.01488">Paper</a>, <a href="https://huggingface.co/colbert-ir/colbertv2.0">HuggingFace</a>, <a href="https://python.langchain.com/docs/integrations/retrievers/ragatouille/">LangChain example</a>.</li>
</ul>
</section>
<section id="vector-databases" class="slide level2">
<h2>Vector Databases</h2>
<p>Features to Consider:</p>
<ul>
<li><p><strong>Scalability</strong>: Ability to handle millions or billions of vectors efficiently.</p></li>
<li><p><strong>Query performance</strong>: Fast similarity search with support for approximate nearest neighbors (ANN) algorithms.</p></li>
<li><p><strong>Similarity search algorithms</strong>: Support for different distance metrics (cosine, euclidean) and indexing methods.</p></li>
<li><p><strong>Metadata filtering</strong>: Ability to combine vector similarity search with metadata filters.</p></li>
<li><p><strong>Cost considerations</strong>: Balance between hosting costs, query costs, and storage requirements.</p></li>
</ul>
</section>
<section id="examples-of-vector-databases" class="slide level2">
<h2>Examples of Vector Databases</h2>
<ul>
<li><strong>Pinecone</strong>:
<ul>
<li>Scalable and high-performance vector database.</li>
<li>Designed for real-time search with high availability and easy integration.</li>
<li>Offers fully managed services with automatic scaling and monitoring.</li>
</ul></li>
<li><strong>Weaviate</strong>:
<ul>
<li>Open-source vector search engine with support for hybrid search (text + vector).</li>
<li>Schema-free or schema-driven, flexible for various data types.</li>
<li>Built-in ML model hosting and extensible through modules like transformers.</li>
</ul></li>
<li><strong>Milvus</strong>:
<ul>
<li>Cloud-native vector database optimized for high-throughput and low-latency vector retrieval.</li>
<li>Open-source with strong community support and enterprise-grade features.</li>
<li>Supports massive-scale data management for AI and analytics applications.</li>
</ul></li>
</ul>
</section>
<section id="examples-of-vector-databases-contd." class="slide level2">
<h2>Examples of Vector Databases (contd.)</h2>
<ul>
<li><strong>Qdrant</strong>:
<ul>
<li>Feature-rich, open-source vector database with support for filtering and hybrid search.</li>
<li>Integrates easily with other tools like LangChain and Python.</li>
<li>Designed for both small-scale and production-grade deployments.</li>
</ul></li>
<li><strong>Vespa</strong>:
<ul>
<li>A scalable engine supporting full-text, vector, and structured data search.</li>
<li>Highly customizable ranking functions for advanced retrieval tasks.</li>
<li>Enterprise-grade features, including sharding and high-availability.</li>
</ul></li>
<li><strong>Redis (with RedisAI)</strong>:
<ul>
<li>Extends Redis key-value store to support vector similarity search.</li>
<li>Real-time capabilities with minimal latency and optional AI integration.</li>
<li>Excellent choice for lightweight applications or adding vector search to existing Redis setups.</li>
</ul></li>
</ul>
</section>
<section id="examples-of-vector-databases-contd.-1" class="slide level2">
<h2>Examples of Vector Databases (contd.)</h2>
<ul>
<li><strong>FAISS (by Meta AI)</strong>:
<ul>
<li>A library rather than a traditional database, optimized for similarity search and clustering.</li>
<li>Ideal for applications requiring high-speed vector operations on dense datasets.</li>
<li>Limited to in-memory computation but extremely efficient.</li>
</ul></li>
<li><strong>OpenSearch</strong>:
<ul>
<li>Open-source search and analytics platform with vector search support using k-NN.</li>
<li>Enables hybrid search across text, vector embeddings, and metadata.</li>
<li>Strong integration with Elasticsearch and big data ecosystems.</li>
</ul></li>
<li><strong>Chroma</strong>:
<ul>
<li>Lightweight and developer-friendly embedding store.</li>
<li>Designed for rapid prototyping and easy integration with LLM applications.</li>
<li>Optimized for smaller-scale use cases but growing in capabilities.</li>
</ul></li>
<li><strong>PostgreSQL (with pgvector)</strong>:
<ul>
<li>Extends PostgreSQL to store and retrieve high-dimensional vector embeddings.</li>
<li>Leverages PostgreSQL’s powerful query capabilities, indexes, and extensions.</li>
<li>Suitable for teams already using PostgreSQL for traditional relational data.</li>
</ul></li>
</ul>
</section>
<section id="review-introduction-to-rag-architecture" class="slide level2">
<h2><strong>Review: Introduction to RAG &amp; Architecture</strong></h2>
<h3 id="building-a-basic-rag-app-1"><strong>Building a Basic RAG App</strong></h3>
<ol type="1">
<li><strong>Prepare documents</strong> → Clean and preprocess content.</li>
<li><strong>Create embeddings</strong> → Use models like BGE, OpenAI, Titan, Cohere.</li>
<li><strong>Store in vector DB</strong> → Pinecone, FAISS, Weaviate, etc.</li>
<li><strong>Retrieve relevant context</strong> → Use similarity search.</li>
<li><strong>Generate response</strong> → Combine retrieved content with LLM prompts.</li>
</ol>
</section>
<section id="review-key-techniques-rag-ecosystem" class="slide level2">
<h2><strong>Review: Key Techniques &amp; RAG Ecosystem</strong></h2>
<h3 id="key-techniques-in-rag"><strong>Key Techniques in RAG</strong></h3>
<ul>
<li><strong>Chunking Strategies</strong>: Fixed-size, semantic, paragraph-based; balance size and overlap (10-20%).</li>
<li><strong>Embeddings Considerations</strong>: Model selection (accuracy, cost, multilingual), dimensionality trade-offs, fine-tuning for domains.</li>
<li><strong>Query Processing</strong>: Query rewriting, hybrid search (semantic + lexical), entity extraction.</li>
<li><strong>Evaluation Metrics</strong>: MRR, Precision, Recall, NDGC.</li>
</ul>
<h3 id="vector-databases-1"><strong>Vector Databases</strong></h3>
<ul>
<li><strong>Popular options</strong>: Pinecone, Weaviate, FAISS, Milvus, Qdrant, RedisAI.</li>
<li><strong>Selection criteria</strong>: Scalability, latency, dimensionality support, metadata filtering.</li>
</ul>
</section>
<section id="review-key-techniques-rag-ecosystem-1" class="slide level2">
<h2><strong>Review: Key Techniques &amp; RAG Ecosystem</strong></h2>
<h3 id="rag-pipelines-tools"><strong>RAG Pipelines &amp; Tools</strong></h3>
<ul>
<li><strong>LangChain, LlamaIndex, Haystack</strong>: Modular frameworks for building RAG applications.</li>
<li><strong>Amazon Bedrock Knowledge Bases</strong>: Managed service for scalable RAG deployment.</li>
</ul>
</section>
<section id="moving-beyond-semantic-similarity" class="slide level2">
<h2>Moving beyond semantic similarity</h2>
<ul>
<li><strong>Retrieval-Augmented Generation (RAG)</strong> enhances LLM responses by retrieving external knowledge.</li>
<li>Three primary approaches:
<ul>
<li><strong>Vector Database RAG</strong> (Vector RAG)</li>
<li><strong>Graph-based RAG</strong> (Graph RAG)</li>
<li><strong>Structured Data RAG</strong> (SQL RAG).</li>
</ul></li>
</ul>
</section>
<section id="vector-db-rag-overview" class="slide level2">
<h2>Vector DB RAG: Overview</h2>
<ul>
<li>Stores knowledge as <strong>high-dimensional vectors</strong></li>
<li>Uses <strong>embedding-based similarity search</strong></li>
<li>Common libraries: FAISS, ChromaDB, Weaviate</li>
<li>Strengths:
<ul>
<li>Fast approximate nearest neighbor (ANN) search</li>
<li>Scales well with large corpora</li>
<li>Ideal for <strong>unstructured text retrieval</strong></li>
</ul></li>
</ul>
</section>
<section id="graph-rag-overview" class="slide level2">
<h2>Graph RAG: Overview</h2>
<ul>
<li>Represents knowledge as <strong>entities and relationships</strong></li>
<li>Uses <strong>graph traversal and structured queries</strong></li>
<li>Common tools: Neo4j, Memgraph</li>
<li>Strengths:
<ul>
<li>Captures <strong>contextual relationships</strong></li>
<li>Enables <strong>logical reasoning</strong> over data</li>
<li>Ideal for <strong>structured, interconnected knowledge</strong></li>
</ul></li>
</ul>
</section>
<section id="key-differences" class="slide level2">
<h2>Key Differences</h2>
<table class="caption-top">
<colgroup>
<col style="width: 23%">
<col style="width: 38%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Vector DB RAG</th>
<th>Graph RAG</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Storage</strong></td>
<td>Dense embeddings (vectors)</td>
<td>Nodes &amp; relationships</td>
</tr>
<tr class="even">
<td><strong>Retrieval</strong></td>
<td>Nearest neighbor search</td>
<td>Graph traversal queries</td>
</tr>
<tr class="odd">
<td><strong>Scalability</strong></td>
<td>Efficient for large text</td>
<td>More complex, depends on structure</td>
</tr>
<tr class="even">
<td><strong>Context</strong></td>
<td>Semantic similarity only</td>
<td>Rich, structured context</td>
</tr>
<tr class="odd">
<td><strong>Use Case</strong></td>
<td>Unstructured knowledge</td>
<td>Structured reasoning</td>
</tr>
</tbody>
</table>
</section>
<section id="when-to-use-which" class="slide level2">
<h2>When to Use Which?</h2>
<h3 id="use-vector-db-rag-when"><strong>Use Vector DB RAG When:</strong></h3>
<ul>
<li>✅ Dealing with <strong>unstructured text</strong> (articles, docs)</li>
<li>✅ Need <strong>fast similarity search</strong></li>
<li>✅ No need for explicit relationships</li>
</ul>
<h3 id="use-graph-rag-when"><strong>Use Graph RAG When:</strong></h3>
<ul>
<li>✅ Need <strong>explicit relationships &amp; context</strong></li>
<li>✅ Want to model <strong>causality &amp; dependencies</strong></li>
<li>✅ Working with <strong>structured knowledge graphs</strong></li>
</ul>
</section>
<section id="key-benefits-of-graph-rag-over-vector-rag" class="slide level2">
<h2>Key Benefits of Graph RAG Over Vector RAG</h2>
<ul>
<li>Let’s explore this with an example, consider the Wikipedia entry for <a href="https://en.wikipedia.org/wiki/Niels_Bohr"><code>Niels Bohr</code></a>.</li>
<li>This page has a lot of highly connected data such as where was Bohr born, where did he study, what did he discover, whom did he collaborate with.</li>
<li>Using a vector db to find related information is not efficient.</li>
</ul>

<img data-src="img/bohr.png" class="r-stretch quarto-figure-center"><p class="caption">Bohr</p></section>
<section id="graph-rag-with-an-example" class="slide level2">
<h2>Graph RAG with an example</h2>
<ul>
<li>✅ 1. Structured, Relationship-Based Knowledge Retrieval
<ul>
<li>Graph RAG: Directly retrieves meaningful relationships instead of relying on semantic similarity.</li>
<li>Example: “Who were Bohr’s collaborators, and what did they work on together?”</li>
<li>Graph: <code>MATCH (p:Person {id: "Bohr"})-[:COLLABORATED_WITH]-&gt;(collaborator) RETURN collaborator.id</code></li>
<li>Vector DB: Needs indirect keyword-based similarity, making it less precise.</li>
</ul></li>
<li>✅ 2. Multi-Hop Reasoning for Deep Context
<ul>
<li>Graph RAG: Finds indirect connections across multiple hops.</li>
<li>Example: “Who was Bohr’s mentor’s mentor?”</li>
<li>Graph: <code>MATCH (p:Person {id: "Bohr"})-[:STUDY_UNDER*2]-&gt;(mentor) RETURN mentor.id</code></li>
<li>Vector DB: Needs recursive similarity searches, which are inefficient.</li>
</ul></li>
</ul>
</section>
<section id="graph-rag-with-an-example-1" class="slide level2">
<h2>Graph RAG with an example</h2>
<ul>
<li>✅ 3. More Explainable and Trustworthy
<ul>
<li>Graph RAG: Results can be traced back to explicit relationships.</li>
<li>Vector RAG: Results are based on black-box similarity (hard to explain why a result was retrieved).</li>
<li>Example: If asked, “Why was this document retrieved?”, Graph RAG can explicitly show relationships.</li>
</ul></li>
<li>✅ 4. Query Flexibility: More Than Just Similarity
<ul>
<li>Graph RAG: Supports specific, structured queries (e.g., “Who studied at the same university as Bohr?”).</li>
<li>Vector RAG: Can only find conceptually similar documents, not structured relationships.</li>
</ul></li>
<li>✅ 5. More Efficient for Small, Highly Connected Datasets
<ul>
<li>Graph RAG: Efficient when data has explicit relationships (e.g., scientific collaboration networks).</li>
<li>Vector RAG: More useful for large, unstructured text collections (e.g., generic documents, news).</li>
</ul></li>
</ul>
</section>
<section id="example-finding-relevant-information" class="slide level2">
<h2>Example: Finding Relevant Information</h2>
<p>The vector search for this would have to include potentially several chunks of text and may still not get all the collaborators whereas the graph retrieval would be deterministic and more accurate.</p>
<h3 id="vector-db-rag-query-faiss"><strong>Vector DB RAG Query</strong> (FAISS)</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href=""></a>retriever <span class="op">=</span> vectorstore.as_retriever()</span>
<span id="cb1-2"><a href=""></a>retriever.get_relevant_documents(<span class="st">"Who all did Bohr collaborate with?"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<h3 id="graph-rag-query-cypher-for-memgraph"><strong>Graph RAG Query</strong> (Cypher for Memgraph)</h3>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource cypher number-lines code-with-copy"><code class="sourceCode"><span id="cb2-1"><a href=""></a>MATCH (p:Person {id: "Bohr"})-[:COLLABORATED_WITH]-&gt;(collaborator)</span>
<span id="cb2-2"><a href=""></a> RETURN collaborator.id;</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="sql-rag-structured-data-retrieval" class="slide level2">
<h2>SQL RAG: Structured Data Retrieval</h2>
<ul>
<li>Uses <strong>relational databases (e.g., MySQL, PostgreSQL)</strong> as the knowledge base.</li>
<li>Retrieves information using <strong>SQL queries</strong> instead of vector similarity or graph traversal.</li>
<li>Best for <strong>highly structured, tabular data</strong>.</li>
<li>Example query: we want to find the average trip distance on a given day from our favorite NYC TLC dataset, now this is a question that neither a vector db nor a graph db can answer.</li>
</ul>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href=""></a>SELECT AVG(trip_distance) AS avg_trip_distance</span>
<span id="cb3-2"><a href=""></a>FROM nyc_taxi_data</span>
<span id="cb3-3"><a href=""></a>WHERE DATE(tpep_pickup_datetime) <span class="op">=</span> <span class="st">'2024-12-11'</span><span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Works well when LLMs can generate SQL queries dynamically based on natural language input.</li>
</ul>
</section>
<section id="langchain-connectors-for-sql-databases" class="slide level2">
<h2>LangChain Connectors for SQL Databases</h2>
<ul>
<li><strong>LangChain</strong> provides integrations for querying SQL databases with LLMs.</li>
<li>Supported databases:
<ul>
<li>MySQL</li>
<li>PostgreSQL</li>
<li>SQLite</li>
<li>Microsoft SQL Server</li>
</ul></li>
</ul>
</section>
<section id="langchain-connectors-for-sql-databases-1" class="slide level2">
<h2>LangChain Connectors for SQL Databases</h2>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href=""></a><span class="im">from</span> langchain.sql_database <span class="im">import</span> SQLDatabase</span>
<span id="cb4-2"><a href=""></a><span class="im">from</span> langchain.chains <span class="im">import</span> SQLDatabaseChain</span>
<span id="cb4-3"><a href=""></a><span class="im">from</span> langchain_aws <span class="im">import</span> ChatBedrockConverse</span>
<span id="cb4-4"><a href=""></a><span class="im">import</span> boto3</span>
<span id="cb4-5"><a href=""></a></span>
<span id="cb4-6"><a href=""></a><span class="co"># Initialize Bedrock client</span></span>
<span id="cb4-7"><a href=""></a>bedrock <span class="op">=</span> boto3.client(</span>
<span id="cb4-8"><a href=""></a>    service_name<span class="op">=</span><span class="st">'bedrock-runtime'</span>,</span>
<span id="cb4-9"><a href=""></a>    region_name<span class="op">=</span><span class="st">'us-east-1'</span>  <span class="co"># replace with your region</span></span>
<span id="cb4-10"><a href=""></a>)</span>
<span id="cb4-11"><a href=""></a></span>
<span id="cb4-12"><a href=""></a><span class="co"># Initialize the LLM</span></span>
<span id="cb4-13"><a href=""></a>llm <span class="op">=</span> ChatBedrockConverse(</span>
<span id="cb4-14"><a href=""></a>    model_id<span class="op">=</span><span class="st">"anthropic.claude-3-sonnet-20240229"</span>,  <span class="co"># or your preferred Claude model</span></span>
<span id="cb4-15"><a href=""></a>    client<span class="op">=</span>bedrock,</span>
<span id="cb4-16"><a href=""></a>    model_kwargs<span class="op">=</span>{<span class="st">"temperature"</span>: <span class="dv">0</span>}</span>
<span id="cb4-17"><a href=""></a>)</span>
<span id="cb4-18"><a href=""></a></span>
<span id="cb4-19"><a href=""></a><span class="co"># Connect to database</span></span>
<span id="cb4-20"><a href=""></a>db <span class="op">=</span> SQLDatabase.from_uri(<span class="st">"sqlite:///example.db"</span>)</span>
<span id="cb4-21"><a href=""></a></span>
<span id="cb4-22"><a href=""></a><span class="co"># Create the chain</span></span>
<span id="cb4-23"><a href=""></a>sql_chain <span class="op">=</span> SQLDatabaseChain.from_llm(llm<span class="op">=</span>llm, database<span class="op">=</span>db, verbose<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-24"><a href=""></a></span>
<span id="cb4-25"><a href=""></a><span class="co"># Run the query</span></span>
<span id="cb4-26"><a href=""></a>sql_chain.run(<span class="st">"What are the top 5 research topics?"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Enables <strong>natural language to SQL translation</strong> for intelligent retrieval from structured datasets.</li>
</ul>
</section>
<section id="summary-of-different-types-of-rag-on-text-data" class="slide level2">
<h2>Summary of different types of RAG on text data</h2>
<ul>
<li><strong>Vector DB RAG</strong> → Best for <strong>scalable, unstructured text search</strong></li>
<li><strong>Graph RAG</strong> → Best for <strong>structured reasoning &amp; entity relationships</strong></li>
<li><strong>SQL RAG</strong> → Best for <strong>highly structured, tabular data</strong></li>
<li><strong>Hybrid RAG</strong> → Best of all approaches!</li>
</ul>
</section>
<section id="multimodal-rag-beyond-text" class="slide level2">
<h2>Multimodal RAG: Beyond Text</h2>
<h3 id="what-is-multimodal-rag">What is Multimodal RAG?</h3>
<ul>
<li>Traditional RAG (Retrieval-Augmented Generation) enhances LLM responses by retrieving relevant text documents</li>
<li>Multimodal RAG extends this to include images, audio, video, and other data formats</li>
<li>Enables LLMs to ground responses in multi-format knowledge sources</li>
</ul>
</section>
<section id="multimodal-rag-key-components" class="slide level2">
<h2>Multimodal RAG: Key Components</h2>
<h3 id="vector-stores">Vector Stores</h3>
<ul>
<li>Specialized embeddings for different modalities</li>
<li>Cross-modal similarity search</li>
<li>Efficient indexing of heterogeneous data</li>
</ul>
<h3 id="embedding-models">Embedding Models</h3>
<ul>
<li>CLIP for image-text embeddings</li>
<li>Whisper for audio-text conversion</li>
<li>Domain-specific models for specialized data types</li>
</ul>
</section>
<section id="architecture-deep-dive" class="slide level2">
<h2>Architecture Deep Dive</h2>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource mermaid number-lines code-with-copy"><code class="sourceCode"><span id="cb5-1"><a href=""></a>graph TD</span>
<span id="cb5-2"><a href=""></a>    A[Input Query] --&gt; B[Query Encoder]</span>
<span id="cb5-3"><a href=""></a>    B --&gt; C[Cross-Modal Vector Search]</span>
<span id="cb5-4"><a href=""></a>    D[Image Database] --&gt; C</span>
<span id="cb5-5"><a href=""></a>    E[Text Database] --&gt; C</span>
<span id="cb5-6"><a href=""></a>    F[Audio Database] --&gt; C</span>
<span id="cb5-7"><a href=""></a>    C --&gt; G[Context Assembly]</span>
<span id="cb5-8"><a href=""></a>    G --&gt; H[LLM]</span>
<span id="cb5-9"><a href=""></a>    H --&gt; I[Enhanced Response]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="implementation-challenges" class="slide level2">
<h2>Implementation Challenges</h2>
<ol type="1">
<li>Modal Alignment
<ul>
<li>Ensuring coherent representation across modalities</li>
<li>Handling modality-specific nuances</li>
<li>Balancing retrieval across different data types</li>
</ul></li>
<li>Performance Considerations
<ul>
<li>Embedding computation overhead</li>
<li>Storage requirements for multi-modal vectors</li>
<li>Retrieval latency management</li>
</ul></li>
</ol>
</section>
<section id="real-world-applications" class="slide level2">
<h2>Real-World Applications</h2>
<h3 id="healthcare">Healthcare</h3>
<ul>
<li>Medical imaging + clinical notes</li>
<li>Patient history + diagnostic images</li>
<li>Treatment protocols + procedural videos</li>
</ul>
<h3 id="e-commerce">E-commerce</h3>
<ul>
<li>Product images + descriptions</li>
<li>Customer reviews + product photos</li>
<li>Usage tutorials + documentation</li>
</ul>
</section>
<section id="best-practices" class="slide level2">
<h2>Best Practices</h2>
<ol type="1">
<li>Data Preprocessing
<ul>
<li>Standardize input formats</li>
<li>Quality filters for each modality</li>
<li>Balanced representation</li>
</ul></li>
<li>Retrieval Strategy
<ul>
<li>Modal-specific relevance scoring</li>
<li>Hybrid retrieval approaches</li>
<li>Context window optimization</li>
</ul></li>
</ol>
</section>
<section id="evaluation-metrics" class="slide level2">
<h2>Evaluation Metrics</h2>
<table class="caption-top">
<colgroup>
<col style="width: 38%">
<col style="width: 61%">
</colgroup>
<thead>
<tr class="header">
<th>Metric</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Cross-Modal Relevance</td>
<td>Alignment between retrieved items across modalities</td>
</tr>
<tr class="even">
<td>Response Coherence</td>
<td>Integration of multi-modal information in outputs</td>
</tr>
<tr class="odd">
<td>Retrieval Latency</td>
<td>Time to fetch and process multi-modal context</td>
</tr>
<tr class="even">
<td>Memory Usage</td>
<td>Resource requirements for different modalities</td>
</tr>
</tbody>
</table>
</section>
<section id="future-directions" class="slide level2">
<h2>Future Directions</h2>
<h3 id="research-opportunities">Research Opportunities</h3>
<ul>
<li>Zero-shot cross-modal transfer</li>
<li>Efficient multi-modal indexing</li>
<li>Context compression techniques</li>
</ul>
<h3 id="emerging-applications">Emerging Applications</h3>
<ul>
<li>Multimodal reasoning</li>
<li>Cross-modal fact verification</li>
<li>Interactive learning systems</li>
</ul>
</section>
<section id="references" class="slide level2">
<h2>References</h2>
<ol type="1">
<li><a href="https://aws.amazon.com/blogs/machine-learning/talk-to-your-slide-deck-using-multimodal-foundation-models-hosted-on-amazon-bedrock-and-amazon-sagemaker-part-1/">Talk to your slide deck: AWS blog post</a></li>
<li><a href="https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base.html">Retrieve data and generate AI responses with Amazon Bedrock Knowledge Bases</a></li>
<li><a href="https://github.com/gu-dsan6725/bookmarks/tree/main?tab=readme-ov-file#rag">Course Bookmarks repo: links for RAG</a></li>
<li><a href="https://arxiv.org/pdf/2106.13884">Multimodal Few-Shot Learning with Frozen Language Models (2023)</a></li>
<li><a href="https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language.pdf">Learning Transferable Visual Models From Natural Language Supervision</a></li>
<li><a href="https://arxiv.org/pdf/2302.00923">Multimodal Chain-of-Thought Reasoning in Language Models</a></li>
</ol>

</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="week-03-rag_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="week-03-rag_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="week-03-rag_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="week-03-rag_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="week-03-rag_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="week-03-rag_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="week-03-rag_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="week-03-rag_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="week-03-rag_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="week-03-rag_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'print',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>